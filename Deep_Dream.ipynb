{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dream\n",
    "## Introduction\n",
    "In this notebook we are going to implement **Deep Dream** algorithm in **Keras**. This algorithm allows to generate art-like images from an initial image by adding activations filters through the process of gradient ascent of the trained model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='city.jpg' style='height:320px; width:550px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='city_dream.png' style='height:320px; width:550px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `import` convolutional base for our model pretrained on `imagenet`(weights='imagenet') dataset without fully-connected layers (include_top=False) and set learning phase to be zero (we are not going to train the model). In this case we are going to use **Inception v3** model rather than **Inception** of the first version how it was proposed in the [initial article](https://ai.googleblog.com/2015/07/deepdream-code-example-for-visualizing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "K.set_learning_phase(0)\n",
    "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we should choose layers with which we are going to make gradient ascents, thus let's look at the structure of the model and choose 'concatenation' ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 3 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 3 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 3 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 3 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 3 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 6 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 6 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 6 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 8 5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 8 240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 8 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 6 192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 6 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 9 55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 4 144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 9 288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 4 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 9 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, None, None, 1 0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 6 76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 9 82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 6 192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 6 192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 9 288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 3 96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 6 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 6 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 9 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 3 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 6 192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 6 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 9 55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 4 144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 9 288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 4 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 9 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 6 76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 9 82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 6 192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 6 192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 9 288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 6 192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 6 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 6 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 9 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 6 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 6 192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 6 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 9 55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 4 144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 9 288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 4 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 9 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 6 76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 9 82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 6 192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 6 192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 9 288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 6 192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 6 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 6 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 9 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 6 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 6 192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 6 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 9 55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 9 288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 9 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 9 82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 3 1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 9 288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 3 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 9 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 1 576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 1 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 1 258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 1 576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 1 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 1 258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 1 576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 1 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 1 258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 1 258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 1 576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 1 576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 1 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 1 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 1 258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 1 576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 1 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 1 258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 1 576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 1 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 3 552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 1 331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 3 960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 1 576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 3 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 1 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 4 1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 4 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 3 1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 3 1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 3 1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 3 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 3 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 3 1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 3 1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 3 1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 3 1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 3 960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 3 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 3 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 3 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 3 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 3 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 7 0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 4 1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 4 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 3 1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 3 1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 3 1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 3 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 3 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 3 1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 3 1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 3 1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 3 1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 3 960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 3 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 3 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 3 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 3 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 3 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 7 0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I choosed first **ten `mixed` layers** to have deal with their filters but I am going to work just with the **five layers somewhere in the middle**(first 'concatenation' layers extract just simple geometrical features from the images but our goal is to derrive from the picture more complex ones and map it on our image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\n",
    "#'mixed0': 0.8,\n",
    "#'mixed1': 0.7,\n",
    "'mixed2': 0.2,\n",
    "'mixed3': 2.4,\n",
    "'mixed4': 1.7,\n",
    "'mixed5': 1.5,\n",
    "'mixed6': 0.9,\n",
    "#'mixed7': 0.9,\n",
    "#'mixed8': 1.5,\n",
    "#'mixed9': 2.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output shape of choosed layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, 288]\n",
      "[None, None, None, 768]\n",
      "[None, None, None, 768]\n",
      "[None, None, None, 768]\n",
      "[None, None, None, 768]\n"
     ]
    }
   ],
   "source": [
    "for layer in layers:\n",
    "    print(model.get_layer(layer).output.shape.as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we should accumulate normalized `loss` value of the choosed layers. The slice of the `activation` we are going to use is of size $((h-4)\\times(w-4)$ - `activation[:, 2: -2, 2: -2, :]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "loss = K.variable(0.)\n",
    "for layer in layers:\n",
    "    coeff = layers[layer]\n",
    "    activation = model.get_layer(layer).output\n",
    "    loss = loss + coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / K.prod(K.cast(K.shape(activation), 'float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **retrive gradients and losses** from the model we create a **function in Keras**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_input = model.input\n",
    "grads = K.gradients(loss, dream_input)[0]\n",
    "grads = grads / K.maximum(K.mean(K.abs(grads)), 1e-10) # Normalize gradients\n",
    "outputs = [loss, grads]\n",
    "function = K.function([dream_input], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the value of loss we create evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x):\n",
    "    outs = function([x])\n",
    "    loss = outs[0]\n",
    "    grad = outs[1]\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And eventually create the most important function to provide `gradient ascent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(image, iterations, lr, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss, grad = evaluate(image)\n",
    "        if max_loss is not None and loss > max_loss:\n",
    "            break\n",
    "        print('iteration: {} ----- loss: {}'.format(i, loss))\n",
    "        image += lr * grad\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ",where `lr` is equivalent to learning rate when we train a Neural Net, thus has approximately the same value ($\\approx 5\\cdot10^{-3}\\div5\\cdot10^{-4}$) and `max_loss` is hyperparameter that directly affects on how much we change the structure of choosed image ($\\approx 10 \\div 50$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's also create functions to work with the image:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with one image but resized differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, size):\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    image = np.copy(image)\n",
    "    factors = (1, float(size[0]) / image.shape[1],\n",
    "               float(size[1]) / image.shape[2], 1)\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we `deprocess` the image to have pexel values from `zero` to `255`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(image):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        image = image.reshape((3, image.shape[2], image.shape[3]))\n",
    "        image = image.transpose((1, 2, 0))\n",
    "    else:\n",
    "        image = image.reshape((image.shape[1], image.shape[2], 3))\n",
    "    image /= 2.\n",
    "    image += 0.5\n",
    "    image *= 255.\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save new image (maped with the grads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(image, name):\n",
    "    import imageio\n",
    "    import numpy as np\n",
    "    dep_image = deprocess(np.copy(image))\n",
    "    imageio.imwrite(name, dep_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we `preprocess` the `initial image` we expand its dimension (image is of shape **(height, width, 3)** but the `input` of the model is 4-dimensional tensor (*batch of images*) of shape **(num_images, height, width, 3)**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images_path):\n",
    "    from keras.preprocessing import image as img\n",
    "    image = img.load_img(images_path)\n",
    "    image = img.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = inception_v3.preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we load our initial image and choose the `number of octave` - number of generated images with different size and calculate their `shapes`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "image = preprocess('paris.jpeg')\n",
    "initial_shape = image.shape[1:3]\n",
    "shapes = [initial_shape]\n",
    "\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in initial_shape])\n",
    "    shapes.append(shape)\n",
    "    \n",
    "shapes = shapes[::-1]\n",
    "initial_image = np.copy(image)\n",
    "shrunk_initial_image = resize(image, shapes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And eventually we run the process of `gradient ascent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note!\n",
    "There is a problem when you reshape the `initial image` upside (from the image of small size ($S$) into big one ($B$)). During the process of resizing you lost some pixels (information about particular details). To prevent that or to add needed details we took into consideration the `initial image` of size $B$:\n",
    "```python\n",
    "image = gradient_ascent(image, iterations=..., lr=..., max_loss=...)\n",
    "lost_details = initial_image_of_size_B - upscaled_shrunk_initial_of_size_B\n",
    "image = image + lost_details\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Processing image of shape:  (551, 1224)\n",
      "---------------------------------------\n",
      "iteration: 0 ----- loss: 1.9878239631652832\n",
      "iteration: 1 ----- loss: 2.5178980827331543\n",
      "iteration: 2 ----- loss: 3.181368112564087\n",
      "iteration: 3 ----- loss: 3.8393945693969727\n",
      "iteration: 4 ----- loss: 4.466948509216309\n",
      "iteration: 5 ----- loss: 5.073509216308594\n",
      "iteration: 6 ----- loss: 5.658028602600098\n",
      "iteration: 7 ----- loss: 6.235952377319336\n",
      "iteration: 8 ----- loss: 6.793768882751465\n",
      "iteration: 9 ----- loss: 7.353477954864502\n",
      "iteration: 10 ----- loss: 7.895106315612793\n",
      "iteration: 11 ----- loss: 8.410794258117676\n",
      "iteration: 12 ----- loss: 8.932978630065918\n",
      "iteration: 13 ----- loss: 9.41873836517334\n",
      "iteration: 14 ----- loss: 9.916206359863281\n",
      "iteration: 15 ----- loss: 10.4071044921875\n",
      "iteration: 16 ----- loss: 10.85922908782959\n",
      "iteration: 17 ----- loss: 11.323277473449707\n",
      "iteration: 18 ----- loss: 11.761119842529297\n",
      "iteration: 19 ----- loss: 12.209047317504883\n",
      "iteration: 20 ----- loss: 12.648988723754883\n",
      "iteration: 21 ----- loss: 13.071513175964355\n",
      "iteration: 22 ----- loss: 13.484729766845703\n",
      "iteration: 23 ----- loss: 13.903436660766602\n",
      "iteration: 24 ----- loss: 14.308808326721191\n",
      "iteration: 25 ----- loss: 14.695775032043457\n",
      "iteration: 26 ----- loss: 15.100812911987305\n",
      "iteration: 27 ----- loss: 15.482603073120117\n",
      "iteration: 28 ----- loss: 15.880928993225098\n",
      "iteration: 29 ----- loss: 16.25625228881836\n",
      "iteration: 30 ----- loss: 16.646163940429688\n",
      "iteration: 31 ----- loss: 16.9921932220459\n",
      "iteration: 32 ----- loss: 17.37822723388672\n",
      "iteration: 33 ----- loss: 17.746017456054688\n",
      "iteration: 34 ----- loss: 18.1204776763916\n",
      "iteration: 35 ----- loss: 18.461563110351562\n",
      "iteration: 36 ----- loss: 18.809776306152344\n",
      "iteration: 37 ----- loss: 19.141820907592773\n",
      "iteration: 38 ----- loss: 19.511306762695312\n",
      "iteration: 39 ----- loss: 19.84775161743164\n",
      "iteration: 40 ----- loss: 20.18528938293457\n",
      "iteration: 41 ----- loss: 20.520620346069336\n",
      "iteration: 42 ----- loss: 20.870851516723633\n",
      "iteration: 43 ----- loss: 21.20616912841797\n",
      "iteration: 44 ----- loss: 21.516481399536133\n",
      "iteration: 45 ----- loss: 21.848234176635742\n",
      "iteration: 46 ----- loss: 22.178266525268555\n",
      "iteration: 47 ----- loss: 22.501760482788086\n",
      "iteration: 48 ----- loss: 22.828821182250977\n",
      "iteration: 49 ----- loss: 23.126129150390625\n",
      "iteration: 50 ----- loss: 23.45821762084961\n",
      "iteration: 51 ----- loss: 23.764617919921875\n",
      "iteration: 52 ----- loss: 24.092185974121094\n",
      "iteration: 53 ----- loss: 24.39189910888672\n",
      "iteration: 54 ----- loss: 24.709068298339844\n",
      "iteration: 55 ----- loss: 25.004138946533203\n",
      "iteration: 56 ----- loss: 25.316282272338867\n",
      "iteration: 57 ----- loss: 25.61852264404297\n",
      "iteration: 58 ----- loss: 25.931867599487305\n",
      "iteration: 59 ----- loss: 26.221179962158203\n",
      "---------------------------------------\n",
      "Processing image of shape:  (771, 1714)\n",
      "---------------------------------------\n",
      "iteration: 0 ----- loss: 3.484814405441284\n",
      "iteration: 1 ----- loss: 5.020943641662598\n",
      "iteration: 2 ----- loss: 6.372173309326172\n",
      "iteration: 3 ----- loss: 7.550013542175293\n",
      "iteration: 4 ----- loss: 8.601774215698242\n",
      "iteration: 5 ----- loss: 9.561971664428711\n",
      "iteration: 6 ----- loss: 10.449272155761719\n",
      "iteration: 7 ----- loss: 11.27575969696045\n",
      "iteration: 8 ----- loss: 12.053581237792969\n",
      "iteration: 9 ----- loss: 12.817195892333984\n",
      "iteration: 10 ----- loss: 13.54654598236084\n",
      "iteration: 11 ----- loss: 14.253963470458984\n",
      "iteration: 12 ----- loss: 14.959648132324219\n",
      "iteration: 13 ----- loss: 15.690226554870605\n",
      "iteration: 14 ----- loss: 16.430912017822266\n",
      "iteration: 15 ----- loss: 17.210613250732422\n",
      "iteration: 16 ----- loss: 18.085323333740234\n",
      "iteration: 17 ----- loss: 19.128297805786133\n",
      "iteration: 18 ----- loss: 20.396621704101562\n",
      "iteration: 19 ----- loss: 21.908056259155273\n",
      "iteration: 20 ----- loss: 23.925758361816406\n",
      "iteration: 21 ----- loss: 26.737213134765625\n",
      "iteration: 22 ----- loss: 30.90342903137207\n",
      "iteration: 23 ----- loss: 36.61810302734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79777\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Processing image of shape:  (1080, 2400)\n",
      "---------------------------------------\n",
      "iteration: 0 ----- loss: 8.784514427185059\n",
      "iteration: 1 ----- loss: 16.314661026000977\n",
      "iteration: 2 ----- loss: 26.285091400146484\n"
     ]
    }
   ],
   "source": [
    "for shape in shapes:\n",
    "    print('---------------------------------------')\n",
    "    print('Processing image of shape: ', shape)\n",
    "    print('---------------------------------------')\n",
    "    image = resize(image, shape)\n",
    "    image = gradient_ascent(image, iterations=60, lr=0.01, max_loss=40)\n",
    "    upscaled_shrunk_initial = resize(shrunk_initial_image, shape)\n",
    "    same_size_initial = resize(initial_image, shape)\n",
    "    lost_detail = same_size_initial - upscaled_shrunk_initial\n",
    "    image += lost_detail\n",
    "    shrunk_initial_image = resize(initial_image, shape)\n",
    "    save(image, name='dream_at_scale_' + str(shape) + '.png')\n",
    "save(image, name='paris_dream.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='paris.jpeg' style='height:320px; width:630px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='paris_dream.png' style='height:320px; width:630px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! Now you can try it with different values of `hyperparameters` like `iterations, lr, max_loss`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
